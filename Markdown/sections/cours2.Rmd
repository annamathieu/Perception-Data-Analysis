---
title: "cours2"
author: "M2 Stat optional class Analyse de données de Perception"
date: "`r Sys.Date()`"
output: html_document
---

# Unfolding 
## Rappel sur les données d'unfolding 

Le point de départ c'est un jeux de données avec en ligne les individus, en colonne les stimuli et au croisement des lignes et des colonnes le classement / le rang attribué par l'individus au stimuli.  

Dans ce jeu de données, chaque ligne est une distance à un idéal.

L'objectif de l'unfolding c'est de représenter dans un même espace les idéaux des individus et les assertions. Sur cette espace on a donc les coordonnées des idéaux.  

Le but de l'unfolding va être de minimiser la différence entre nos distance observées (les lignes de notre tableau de données ) et nos distances estimée (les coordonnées des points sur notre graphique). Pour faire celà on va avoir besoin d'une déscente de gradient. 

La question se pose de comment on passe de rang à distance. Il expiste plein de métrique différents, mais on peut très simplement dire que le premier à une distance de 1, que le deuxième une distance de deux et ainsi de suite. 

## Notre jeu de données 

Le jeux de données que nous avons ne correspond pas à des données d'unfolding, la structure n'est pas la bonne.   
En colonne nous avons le rang, en ligne l'individus et au croisement le rang.   
Pour pouvoir utiliser le package smacof et réaliser l'unfoldinf, il nous faut en colonne le rang et au croisement entre individus et rang l'assertions. 

Pour faire celà, il faut trier pour chaque ligne les assertions par ordre alphabétique et récupérer les rangs correspondants. 

Chaque groupe à réaliser celà d'une manière différente : 

```{r}
# proposition : 


```




Le package *smacof* permet de réaliser l'unfolding. Il faut utiliser la fonction unfolding. 

La limite de ce package est qu'il ne prend pas en compte les variables supplémentaire. Il faut donc ruser pour améliorer notre graphique et y rajouter les variables supplémentaire. 

Pour ce faire on fait un tableau de données intermédiaire ou on fait correspondre les coordonnées de chaque indivuds et les valeurs prise par les variable supplémentaire. Ensuite on calcul par modalité de chacune des variables supplémentaire le barycentre. 

```{r}
supw <- cbind(sup,un_folding$conf.row[2:47,])
supw[,1]<-as.factor(supw[,1])
supw[,2]<-as.factor(supw[,2])
supw[,3]<-as.factor(supw[,3])
summary(supw)


points_moyens_responsabilite <- aggregate(
  x = supw[, c("D1", "D2")], # Les variables sur lesquelles calculer la moyenne
  by = list(Responsabilite = supw$Responsabilite), # La variable de regroupement
  FUN = mean # La fonction à appliquer (la moyenne)
)

points_moyens_sentiment <- aggregate(
  x = supw[, c("D1", "D2")], # Les variables sur lesquelles calculer la moyenne
  by = list(Sentiment = supw$Sentiment), # La variable de regroupement
  FUN = mean # La fonction à appliquer (la moyenne)
)
```

```{r}
# Ajouter de la data illustrative 
illus <- atomic[,c(1,20:21)]
names(illus)[2:3] <- c("Responsabilite_env", "Sentiment_env")  

illus[,1:3] <- lapply(illus, as.factor)

levels(illus$Responsabilite_env) <- c("pas_du_tout_responsable", "peu_responsable", "moy_responsable", "responsable", "tres_responsable")

# nrow(illus)
# nrow(group1)

new_data <- cbind(as.data.frame(unfolded$conf.row[-1,]), illus[,-1])
```

Création du graph 
=> construit à partir des profils idéaux 
```{r}
assertions_long <- names(resultat)

fig <- plot_ly() %>%
  
  # Individus
  add_trace(data = conf_ind,
            x = ~D1, y = ~D2,
            type = 'scatter', mode = 'markers',
            marker = list(color = 'black', size = 5),
            name = 'Individus') %>%
  
  # Assertions
  add_trace(data = conf_assertions,
            x = ~D1, y = ~D2,
            type = 'scatter', mode = 'markers+text',
            marker = list(color = 'cadetblue', size = 5),
            text = ~rownames(conf_assertions),
            textfont = list(color = 'cadetblue'),
            textposition = 'top center',
            hovertext = ~assertions_long,  # texte au survol
            hoverinfo = 'text',
            name = 'Assertions') %>%
  
  # Responsabilité environnementale
  add_trace(data = points_moyens_responsabilite,
            x = ~D1, y = ~D2,
            type = 'scatter', mode = 'markers+text',
            marker = list(color = 'red', size = 5),
            text = ~levels(illus$Responsabilite_env),
            textfont = list(color = 'red'),
            textposition = 'top center',
            name = 'Responsabilité') %>%
  
  # Sentiment environnemental
  add_trace(data = points_moyens_sentiment,
            x = ~D1, y = ~D2,
            type = 'scatter', mode = 'markers+text',
            marker = list(color = 'green', size = 5),
            text = ~levels(illus$Sentiment_env)[-1],
            textfont = list(color = 'green'),
            textposition = 'top center',
            name = 'Sentiment') %>%
  

  layout(title = list(text = "Unfolding Configuration", x = 0.5),
         xaxis = list(title = ""),
         yaxis = list(title = ""),
         plot_bgcolor = 'rgb(242, 242, 242)',
         showlegend = TRUE)

fig
```


## Description de notre graphique





# Profil idéal

Un profil sensoriel c'est un ensemble de caractéristiques évaluées par nos sens. Un profil idéal est un profil particulier: un ensemble de caractéristiques qui maximisent le liking (appréciation hédonique) d'un produit (ou autre objet étudié).

Pour créer un profil idéal, on réunit un panel de consommateurs qui vont évaluer des produits sur des descripteurs. En plus de ces descripteurs il leur est demandé de donner une note d'appréciation hédonique et de remplir un profil idéal pour le produit. Ce profil idéal correspond au niveau idéal d'un descripteur pour un consommateur. Un consommateur peut avoir un, ou plusieurs idéaux.  

La première étape dans ce cas est de regarder la consistence de notre jeu de données. 

Le bloc de données le plus fragile est le bloc du profil idéal car c'est très très subjectif. En effet, le consommateur a évalué d'une part : 
- les profils sensoriels des produits : attributs sensoriels sur des produits physiques
- son appréciation hédonique de chacun de ces produits : réponse spontanée à un instant T sur un produit présenté
- évaluation des profils idéaux : le niveau que devrait prendre l'attribut sensoriel pour atteindre le niveau idéal pour ce consommateur, donc ces mesures sont réalisées à partir de produits imaginaires et sont très subjectives.

De plus, on ne connait pas l'appréciation hédonique perçue par le consommateur d'un produit qui correspondrait à ce profil idéal. 

Il faut que l'appréciation du produit idéal dépasse l'appréciation des produits évalués car les produits idéaux maximisent le liking.



## Première vérification consistence des juges 

Un idéal sous entend que l'on préfère l'idéal au produit présenté. On peut verifier celà en faisant pour chaque individus un modèle de prédiction de liking. L'utiliser pour estimer la note attribué à ses profils idéaux et regarder si ces notes sont meilleurs que celle de la réalité. 

## Deuxième verification consistence sensorielle 

L'avantage dans la méthode du profil idéal c'est qu'à l'inverse du préférence mapping, les profils sensoriels et les données hédonique sont appareillées. 


## Troisième verification corrélation




# Profil idéal exemple des politiques publiques

On essaie d'adopter la méthodologie de profil idéal à un tout autre sujet, les politiques publiques. Il faut transformer les différents éléments et les adapter à ce sujet : 

- 
